{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c5bd0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in d:\\anaconda1\\lib\\site-packages (4.35.0)\n",
      "Requirement already satisfied: filelock in d:\\anaconda1\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in d:\\anaconda1\\lib\\site-packages (from transformers) (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\anaconda1\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda1\\lib\\site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\anaconda1\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\anaconda1\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in d:\\anaconda1\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in d:\\anaconda1\\lib\\site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in d:\\anaconda1\\lib\\site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\anaconda1\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in d:\\anaconda1\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\anaconda1\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.6.3)\n",
      "Requirement already satisfied: colorama in d:\\anaconda1\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda1\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda1\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda1\\lib\\site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda1\\lib\\site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: torch in d:\\anaconda1\\lib\\site-packages (2.1.0)\n",
      "Requirement already satisfied: filelock in d:\\anaconda1\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in d:\\anaconda1\\lib\\site-packages (from torch) (4.6.3)\n",
      "Requirement already satisfied: sympy in d:\\anaconda1\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in d:\\anaconda1\\lib\\site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda1\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in d:\\anaconda1\\lib\\site-packages (from torch) (2023.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\anaconda1\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in d:\\anaconda1\\lib\\site-packages (from sympy->torch) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b475a2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "# Sentences we want sentence embeddings for\n",
    "sentences = ['This is an example sentence', 'Each sentence is converted']\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# Tokenize sentences\n",
    "encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Compute token embeddings\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "\n",
    "# Perform pooling\n",
    "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "# Normalize embeddings\n",
    "sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "\n",
    "print(\"Sentence embeddings:\")\n",
    "print(sentence_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a73cae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1bf5f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0]\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ded7667e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['This is an example sentence', 'Each sentence is converted']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c15e148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ea66377bf5e4122b66525361a8a3c7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda1\\Lib\\site-packages\\huggingface_hub\\file_download.py:137: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\phabi\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28b9e0f4d7a24e5cbc2b61a7967c02f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ef4b8496b3644a9a68b8afcf6063fd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3300d0d4ce3841f6a6becf062b145fc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37e2e6faee724a40a996623f077de462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c4b3349ae134001a4bc050055325144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "833fe292",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "addbed74",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8bb96d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence embeddings:\n",
      "tensor([[ 6.7657e-02,  6.3496e-02,  4.8713e-02,  7.9305e-02,  3.7448e-02,\n",
      "          2.6528e-03,  3.9375e-02, -7.0985e-03,  5.9361e-02,  3.1537e-02,\n",
      "          6.0098e-02, -5.2905e-02,  4.0607e-02, -2.5931e-02,  2.9843e-02,\n",
      "          1.1269e-03,  7.3515e-02, -5.0382e-02, -1.2239e-01,  2.3703e-02,\n",
      "          2.9727e-02,  4.2477e-02,  2.5634e-02,  1.9952e-03, -5.6919e-02,\n",
      "         -2.7160e-02, -3.2904e-02,  6.6025e-02,  1.1901e-01, -4.5879e-02,\n",
      "         -7.2621e-02, -3.2584e-02,  5.2341e-02,  4.5055e-02,  8.2530e-03,\n",
      "          3.6702e-02, -1.3942e-02,  6.5392e-02, -2.6427e-02,  2.0642e-04,\n",
      "         -1.3664e-02, -3.6281e-02, -1.9504e-02, -2.8974e-02,  3.9427e-02,\n",
      "         -8.8409e-02,  2.6242e-03,  1.3671e-02,  4.8306e-02, -3.1157e-02,\n",
      "         -1.1733e-01, -5.1169e-02, -8.8529e-02, -2.1896e-02,  1.4299e-02,\n",
      "          4.4417e-02, -1.3482e-02,  7.4339e-02,  2.6638e-02, -1.9876e-02,\n",
      "          1.7919e-02, -1.0605e-02, -9.0426e-02,  2.1327e-02,  1.4120e-01,\n",
      "         -6.4717e-03, -1.4038e-03, -1.5361e-02, -8.7357e-02,  7.2217e-02,\n",
      "          2.0140e-02,  4.2559e-02, -3.4901e-02,  3.1955e-04, -8.0297e-02,\n",
      "         -3.2747e-02,  2.8527e-02, -5.1366e-02,  1.0939e-01,  8.1933e-02,\n",
      "         -9.8404e-02, -9.3410e-02, -1.5129e-02,  4.5125e-02,  4.9417e-02,\n",
      "         -2.5187e-02,  1.5708e-02, -1.2929e-01,  5.3190e-03,  4.0234e-03,\n",
      "         -2.3457e-02, -6.7298e-02,  2.9228e-02, -2.6084e-02,  1.3062e-02,\n",
      "         -3.1166e-02, -4.8271e-02, -5.5886e-02, -3.8751e-02,  1.2001e-01,\n",
      "         -1.0392e-02,  4.8970e-02,  5.5354e-02,  4.4936e-02, -4.0097e-03,\n",
      "         -1.0296e-01, -2.9297e-02, -5.8340e-02,  2.7047e-02, -2.2017e-02,\n",
      "         -7.2224e-02, -4.1387e-02, -1.9330e-02,  2.7332e-03,  2.7703e-04,\n",
      "         -9.6759e-02, -1.0057e-01, -1.4192e-02, -8.0789e-02,  4.5393e-02,\n",
      "          2.4504e-02,  5.9761e-02, -7.3818e-02,  1.1984e-02, -6.6340e-02,\n",
      "         -7.6905e-02,  3.8516e-02, -5.5936e-33,  2.8001e-02, -5.6078e-02,\n",
      "         -4.8660e-02,  2.1557e-02,  6.0198e-02, -4.8140e-02, -3.5025e-02,\n",
      "          1.9331e-02, -1.7515e-02, -3.8921e-02, -3.8106e-03, -1.7029e-02,\n",
      "          2.8210e-02,  1.2829e-02,  4.7160e-02,  6.2103e-02, -6.4359e-02,\n",
      "          1.2929e-01, -1.3123e-02,  5.2307e-02, -3.7368e-02,  2.8910e-02,\n",
      "         -1.6898e-02, -2.3733e-02, -3.3349e-02, -5.1676e-02,  1.5536e-02,\n",
      "          2.0880e-02, -1.2537e-02,  4.5958e-02,  3.7272e-02,  2.8057e-02,\n",
      "         -5.9000e-02, -1.1699e-02,  4.9218e-02,  4.7033e-02,  7.3549e-02,\n",
      "         -3.7053e-02,  3.9846e-03,  1.0641e-02, -1.6150e-04, -5.2717e-02,\n",
      "          2.7593e-02, -3.9292e-02,  8.4472e-02,  4.8686e-02, -4.8587e-03,\n",
      "          1.7995e-02, -4.2857e-02,  1.2338e-02,  6.3996e-03,  4.0482e-02,\n",
      "          1.4889e-02, -1.5394e-02,  7.6295e-02,  2.3704e-02,  4.4524e-02,\n",
      "          5.0820e-02, -2.3125e-03, -1.8874e-02, -1.2334e-02,  4.6600e-02,\n",
      "         -5.6344e-02,  6.2993e-02, -3.1554e-02,  3.2491e-02,  2.3467e-02,\n",
      "         -6.5544e-02,  2.0171e-02,  2.5708e-02, -1.2387e-02, -8.3649e-03,\n",
      "         -6.6438e-02,  9.4307e-02, -3.5709e-02, -3.4248e-02, -6.6635e-03,\n",
      "         -8.0152e-03, -3.0971e-02,  4.3301e-02, -8.2140e-03, -1.5079e-01,\n",
      "          3.0769e-02,  4.0072e-02, -3.7929e-02,  1.9321e-03,  4.0053e-02,\n",
      "         -8.7708e-02, -3.6849e-02,  8.5796e-03, -3.1925e-02, -1.2526e-02,\n",
      "          7.3554e-02,  1.3474e-03,  2.0592e-02,  2.7110e-33, -5.1858e-02,\n",
      "          5.7836e-02, -9.1899e-02,  3.9442e-02,  1.0558e-01, -1.9691e-02,\n",
      "          6.1840e-02, -7.6347e-02,  2.4088e-02,  9.4005e-02, -1.1654e-01,\n",
      "          3.7120e-02,  5.2243e-02, -3.9586e-03,  5.7221e-02,  5.3286e-03,\n",
      "          1.2402e-01,  1.3902e-02, -1.1025e-02,  3.5605e-02, -3.3075e-02,\n",
      "          8.1657e-02, -1.5200e-02,  6.0559e-02, -6.0140e-02,  3.2610e-02,\n",
      "         -3.4830e-02, -1.6988e-02, -9.7491e-02, -2.7148e-02,  1.7471e-03,\n",
      "         -7.6898e-02, -4.3186e-02, -1.8999e-02, -2.9166e-02,  5.7749e-02,\n",
      "          2.4182e-02, -1.1690e-02, -6.2144e-02,  2.8435e-02, -2.3755e-04,\n",
      "         -2.5178e-02,  4.3964e-03,  8.1284e-02,  3.6418e-02, -6.0401e-02,\n",
      "         -3.6552e-02, -7.9375e-02, -5.0853e-03,  6.6970e-02, -1.1778e-01,\n",
      "          3.2374e-02, -4.7125e-02, -1.3446e-02, -9.4844e-02,  8.2495e-03,\n",
      "         -1.0675e-02, -6.8188e-02,  1.1181e-03,  2.4802e-02, -6.3589e-02,\n",
      "          2.8449e-02, -2.6130e-02,  8.5811e-02,  1.1468e-01, -5.3535e-02,\n",
      "         -5.6359e-02,  4.2601e-02,  1.0945e-02,  2.0958e-02,  1.0013e-01,\n",
      "          3.2605e-02, -1.8421e-01, -3.9321e-02, -6.9145e-02, -6.3811e-02,\n",
      "         -6.5639e-02, -6.4125e-03, -4.7961e-02, -7.6813e-02,  2.9538e-02,\n",
      "         -2.2995e-02,  4.1704e-02, -2.5005e-02, -4.5451e-03, -4.1714e-02,\n",
      "         -1.3229e-02, -6.3836e-02, -2.4647e-03, -1.3734e-02,  1.6898e-02,\n",
      "         -6.3040e-02,  8.9888e-02,  4.1817e-02, -1.8569e-02, -1.8044e-08,\n",
      "         -1.6800e-02, -3.2158e-02,  6.3038e-02, -4.1309e-02,  4.4482e-02,\n",
      "          2.0247e-03,  6.2959e-02, -5.1737e-03, -1.0044e-02, -3.0564e-02,\n",
      "          3.5267e-02,  5.5858e-02, -4.6713e-02,  3.4510e-02,  3.2958e-02,\n",
      "          4.3011e-02,  2.9436e-02, -3.0316e-02, -1.7111e-02,  7.3748e-02,\n",
      "         -5.4791e-02,  2.7752e-02,  6.2017e-03,  1.5880e-02,  3.4298e-02,\n",
      "         -5.1575e-03,  2.3508e-02,  7.5313e-02,  1.9284e-02,  3.3620e-02,\n",
      "          5.0910e-02,  1.5250e-01,  1.6421e-02,  2.7053e-02,  3.7516e-02,\n",
      "          2.1855e-02,  5.6633e-02, -3.9575e-02,  7.1231e-02, -5.4138e-02,\n",
      "          1.0377e-03,  2.1185e-02, -3.5631e-02,  1.0902e-01,  2.7653e-03,\n",
      "          3.1400e-02,  1.3842e-03, -3.4574e-02, -4.5928e-02,  2.8808e-02,\n",
      "          7.1691e-03,  4.8468e-02,  2.6102e-02, -9.4407e-03,  2.8217e-02,\n",
      "          3.4872e-02,  3.6910e-02, -8.5895e-03, -3.5321e-02, -2.4786e-02,\n",
      "         -1.9192e-02,  3.8071e-02,  5.9965e-02, -4.2229e-02],\n",
      "        [ 8.6439e-02,  1.0276e-01,  5.3946e-03,  2.0445e-03, -9.9634e-03,\n",
      "          2.5386e-02,  4.9288e-02, -3.0627e-02,  6.8726e-02,  1.0137e-02,\n",
      "          7.7540e-02, -9.0081e-02,  6.1062e-03, -5.6990e-02,  1.4172e-02,\n",
      "          2.8049e-02, -8.6847e-02,  7.6440e-02, -1.0349e-01, -6.7744e-02,\n",
      "          6.9995e-02,  8.4425e-02, -7.2491e-03,  1.0477e-02,  1.3402e-02,\n",
      "          6.7758e-02, -9.4209e-02, -3.7169e-02,  5.2262e-02, -3.1085e-02,\n",
      "         -9.6341e-02,  1.5772e-02,  2.5787e-02,  7.8525e-02,  7.8995e-02,\n",
      "          1.9152e-02,  1.6436e-02,  3.1009e-03,  3.8131e-02,  2.3709e-02,\n",
      "          1.0539e-02, -4.4065e-02,  4.4174e-02, -2.5873e-02,  6.1538e-02,\n",
      "         -4.0543e-02, -8.6414e-02,  3.1972e-02, -8.9068e-04, -2.4444e-02,\n",
      "         -9.1972e-02,  2.3394e-02, -8.3029e-02,  4.4151e-02, -2.4969e-02,\n",
      "          6.2302e-02, -1.3035e-03,  7.5140e-02,  2.4638e-02, -6.4724e-02,\n",
      "         -1.1773e-01,  3.8339e-02, -9.1177e-02,  6.3545e-02,  7.6274e-02,\n",
      "         -8.8024e-02,  9.5456e-03, -4.6972e-02, -8.4174e-02,  3.8882e-02,\n",
      "         -1.1439e-01,  6.2885e-03, -3.4936e-02,  2.3975e-02, -3.3132e-02,\n",
      "         -1.5724e-02, -3.7896e-02, -8.8125e-03,  7.0612e-02,  3.2807e-02,\n",
      "          2.0367e-03, -1.1228e-01,  6.7972e-03,  1.2277e-02,  3.3530e-02,\n",
      "         -1.3620e-02, -2.2549e-02, -2.2523e-02, -2.0319e-02,  5.0430e-02,\n",
      "         -7.4865e-02, -8.2282e-02,  7.6596e-02,  4.9339e-02, -3.7555e-02,\n",
      "          1.4463e-02, -5.7246e-02, -1.7995e-02,  1.0970e-01,  1.1946e-01,\n",
      "          8.0924e-04,  6.1706e-02,  3.2632e-02, -1.3078e-01, -1.4864e-01,\n",
      "         -6.1623e-02,  4.3389e-02,  2.6713e-02,  1.3979e-02, -3.9400e-02,\n",
      "         -2.5271e-02,  3.8775e-03,  3.5866e-02, -6.1542e-02,  3.7666e-02,\n",
      "          2.6757e-02, -3.8266e-02, -3.5479e-02, -2.3923e-02,  8.6798e-02,\n",
      "         -1.8406e-02,  7.7104e-02,  1.3986e-03,  7.0038e-02, -4.7788e-02,\n",
      "         -7.8982e-02,  5.1081e-02, -2.9987e-33, -3.9165e-02, -2.5621e-03,\n",
      "          1.6521e-02,  9.4894e-03, -5.6622e-02,  6.5778e-02, -4.7700e-02,\n",
      "          1.1166e-02, -5.7356e-02, -9.1626e-03, -2.1752e-02, -5.5953e-02,\n",
      "         -1.1142e-02,  9.3279e-02,  1.6677e-02, -1.3672e-02,  4.3439e-02,\n",
      "          1.8724e-03,  7.2995e-03,  5.1633e-02,  4.8061e-02,  1.3534e-01,\n",
      "         -1.7174e-02, -1.2970e-02, -7.5011e-02,  2.6111e-02,  2.6980e-02,\n",
      "          7.8302e-04, -4.8727e-02,  1.1784e-02, -4.5958e-02, -4.8321e-02,\n",
      "         -1.9567e-02,  1.9389e-02,  1.9881e-02,  1.6743e-02,  9.8780e-02,\n",
      "         -2.7409e-02,  2.3481e-02,  3.7023e-03, -6.1451e-02, -1.2123e-03,\n",
      "         -9.5047e-03,  9.2515e-03,  2.3844e-02,  8.6123e-02,  2.2679e-02,\n",
      "          5.4512e-04,  3.4713e-02,  6.2546e-03, -6.9278e-03,  3.9240e-02,\n",
      "          1.1567e-02,  3.2628e-02,  6.2216e-02,  2.7611e-02,  1.8688e-02,\n",
      "          3.5581e-02,  4.1180e-02,  1.5478e-02,  4.2269e-02,  3.8225e-02,\n",
      "          1.0031e-02, -2.8325e-02,  4.4705e-02, -4.1046e-02, -4.5055e-03,\n",
      "         -5.4473e-02,  2.6232e-02,  1.7986e-02, -1.2312e-01, -4.6695e-02,\n",
      "         -1.3591e-02,  6.4671e-02,  3.5735e-03, -1.2223e-02, -1.7938e-02,\n",
      "         -2.5550e-02,  2.3722e-02,  4.0867e-03, -6.5148e-02,  4.4365e-02,\n",
      "          4.6860e-02, -3.2517e-02,  4.0227e-03, -3.9760e-03,  1.1194e-02,\n",
      "         -9.9560e-02,  3.3317e-02,  8.0106e-02,  9.4269e-02, -6.3829e-02,\n",
      "          3.2315e-02, -5.1355e-02, -7.4988e-03,  5.3005e-34, -4.1319e-02,\n",
      "          9.4965e-02, -1.0640e-01,  4.9659e-02, -3.4191e-02, -3.1675e-02,\n",
      "         -1.7156e-02,  1.7010e-03,  5.7976e-02, -1.2178e-03, -1.6854e-02,\n",
      "         -5.1691e-02,  5.5300e-02, -3.4265e-02,  3.0818e-02, -3.1048e-02,\n",
      "          9.2753e-02,  3.7266e-02, -2.3740e-02,  4.4589e-02,  1.4615e-02,\n",
      "          1.1624e-01, -5.0011e-02,  3.8872e-02,  4.2475e-03,  2.5698e-02,\n",
      "          3.2724e-02,  4.2991e-02, -1.3614e-02,  2.5612e-02,  1.0626e-02,\n",
      "         -8.4686e-02, -9.5298e-02,  1.0840e-01, -7.5160e-02, -1.3777e-02,\n",
      "          6.3734e-02, -4.4967e-03, -3.2532e-02,  6.2361e-02,  3.4805e-02,\n",
      "         -3.5492e-02, -2.0022e-02,  3.6661e-02, -2.4884e-02,  1.0182e-02,\n",
      "         -7.0123e-02, -4.3195e-02,  2.9533e-02, -2.9496e-04, -3.4539e-02,\n",
      "          1.4668e-02, -9.8397e-02, -4.7049e-02, -8.8550e-03, -8.8991e-02,\n",
      "          3.5100e-02, -1.2960e-01, -4.9887e-02, -6.1205e-02, -5.9780e-02,\n",
      "          9.4632e-03,  4.9122e-02, -7.7503e-02,  8.0973e-02, -4.7926e-02,\n",
      "          2.3438e-03,  7.5703e-02, -2.4018e-02, -1.5255e-02,  4.8674e-02,\n",
      "         -3.8597e-02, -7.0483e-02, -1.2035e-02, -3.8879e-02, -7.7602e-02,\n",
      "         -1.0724e-02,  1.0419e-02, -2.1375e-02, -9.1739e-02, -1.1134e-02,\n",
      "         -2.9607e-02,  2.4646e-02,  4.6571e-03, -1.6345e-02, -3.9522e-02,\n",
      "          7.7337e-02, -2.8473e-02, -3.6994e-03,  8.2766e-02, -1.1041e-02,\n",
      "          3.1398e-02,  5.3509e-02,  5.7515e-02, -3.1762e-02, -1.5291e-08,\n",
      "         -7.9966e-02, -4.7680e-02, -8.5979e-02,  5.6962e-02, -4.0887e-02,\n",
      "          2.2383e-02, -4.6445e-03, -3.8013e-02, -3.1067e-02, -1.0728e-02,\n",
      "          1.9770e-02,  7.7700e-03, -6.0947e-03, -3.8638e-02,  2.8027e-02,\n",
      "          6.7814e-02, -2.3535e-02,  3.2175e-02,  8.0254e-03, -2.3911e-02,\n",
      "         -1.2200e-03,  3.1460e-02, -5.2492e-02, -8.0681e-03,  3.1477e-03,\n",
      "          5.1150e-02, -4.4410e-02,  6.3601e-02,  3.8508e-02,  3.3043e-02,\n",
      "         -4.1873e-03,  4.9559e-02, -5.6960e-02, -6.4971e-03, -2.4979e-02,\n",
      "         -1.6087e-02,  6.6229e-02, -2.0631e-02,  1.0805e-01,  1.6855e-02,\n",
      "          1.4381e-02, -1.3213e-02, -1.2939e-01,  6.9522e-02, -5.5577e-02,\n",
      "         -6.7541e-02, -5.4582e-03, -6.1360e-03,  3.9084e-02, -6.2878e-02,\n",
      "          3.7406e-02, -1.1657e-02,  1.2915e-02, -5.5250e-02,  5.1608e-02,\n",
      "         -4.3084e-03,  5.8025e-02,  1.8695e-02,  2.2781e-02,  3.2167e-02,\n",
      "          5.3798e-02,  7.0285e-02,  7.4931e-02, -8.4177e-02]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentence embeddings:\")\n",
    "print(sentence_embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d10f0be",
   "metadata": {},
   "source": [
    "# From chat gpt Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f9ba461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in d:\\anaconda1\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in d:\\anaconda1\\lib\\site-packages (from sentence-transformers) (4.35.0)\n",
      "Requirement already satisfied: tqdm in d:\\anaconda1\\lib\\site-packages (from sentence-transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in d:\\anaconda1\\lib\\site-packages (from sentence-transformers) (2.1.0)\n",
      "Requirement already satisfied: torchvision in d:\\anaconda1\\lib\\site-packages (from sentence-transformers) (0.16.0)\n",
      "Requirement already satisfied: numpy in d:\\anaconda1\\lib\\site-packages (from sentence-transformers) (1.24.3)\n",
      "Requirement already satisfied: scikit-learn in d:\\anaconda1\\lib\\site-packages (from sentence-transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in d:\\anaconda1\\lib\\site-packages (from sentence-transformers) (1.10.1)\n",
      "Requirement already satisfied: nltk in d:\\anaconda1\\lib\\site-packages (from sentence-transformers) (3.7)\n",
      "Requirement already satisfied: sentencepiece in d:\\anaconda1\\lib\\site-packages (from sentence-transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in d:\\anaconda1\\lib\\site-packages (from sentence-transformers) (0.17.3)\n",
      "Requirement already satisfied: filelock in d:\\anaconda1\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.9.0)\n",
      "Requirement already satisfied: fsspec in d:\\anaconda1\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.3.0)\n",
      "Requirement already satisfied: requests in d:\\anaconda1\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\anaconda1\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\anaconda1\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.6.3)\n",
      "Requirement already satisfied: packaging>=20.9 in d:\\anaconda1\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.0)\n",
      "Requirement already satisfied: sympy in d:\\anaconda1\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (1.11.1)\n",
      "Requirement already satisfied: networkx in d:\\anaconda1\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda1\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: colorama in d:\\anaconda1\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\anaconda1\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in d:\\anaconda1\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in d:\\anaconda1\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.4.0)\n",
      "Requirement already satisfied: click in d:\\anaconda1\\lib\\site-packages (from nltk->sentence-transformers) (8.0.4)\n",
      "Requirement already satisfied: joblib in d:\\anaconda1\\lib\\site-packages (from nltk->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\anaconda1\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in d:\\anaconda1\\lib\\site-packages (from torchvision->sentence-transformers) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\anaconda1\\lib\\site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda1\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda1\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda1\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda1\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in d:\\anaconda1\\lib\\site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22be891d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5d4a9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folder_path1 = r'C:\\Users\\phabi\\Desktop\\MESTRADO\\FGV\\Materias\\4 Quarto\\AI Bisness\\Downloaded_PDFs\\Teste2\\Vale'\n",
    "file1 = '2013 Sustainability Report.txt'\n",
    "folder_path2 = r'C:\\Users\\phabi\\Desktop\\MESTRADO\\FGV\\Materias\\4 Quarto\\AI Bisness\\Downloaded_PDFs\\Teste2\\Petro'\n",
    "file2 = 'Sustainability_2019.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "647cfa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the content of your documents\n",
    "with open(os.path.join(folder_path1, file1), 'r', encoding='utf-8') as f:\n",
    "    doc1 = f.read()\n",
    "\n",
    "with open(os.path.join(folder_path2, file2), 'r', encoding='utf-8') as f:\n",
    "    doc2 = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b6fccf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings\n",
    "embeddings = model.encode([doc1, doc2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00bb3700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents is: 0.32423847913742065\n"
     ]
    }
   ],
   "source": [
    "# Compute cosine similarity\n",
    "similarity_score = cosine_similarity([embeddings[0]], [embeddings[1]])\n",
    "\n",
    "# Print the similarity score\n",
    "print(f'The cosine similarity between the documents is: {similarity_score[0][0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8cc8a6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = r'C:\\Users\\phabi\\Desktop\\MESTRADO\\FGV\\Materias\\4 Quarto\\AI Bisness\\Downloaded_PDFs\\Teste2'\n",
    "file1 = 'Relato Integrado 2021.txt'\n",
    "file2 = 'Relato Integrado 2022.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60dd43b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents is: 0.4625832140445709\n"
     ]
    }
   ],
   "source": [
    "# Read the content of your documents\n",
    "with open(os.path.join(folder_path, file1), 'r', encoding='utf-8') as f:\n",
    "    doc1 = f.read()\n",
    "\n",
    "with open(os.path.join(folder_path, file2), 'r', encoding='utf-8') as f:\n",
    "    doc2 = f.read()\n",
    "# Generate embeddings\n",
    "embeddings = model.encode([doc1, doc2])\n",
    "# Compute cosine similarity\n",
    "similarity_score = cosine_similarity([embeddings[0]], [embeddings[1]])\n",
    "\n",
    "# Print the similarity score\n",
    "print(f'The cosine similarity between the documents is: {similarity_score[0][0]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
